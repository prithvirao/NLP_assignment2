{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e10dc0ce",
   "metadata": {},
   "source": [
    "# Assignment - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53003de",
   "metadata": {},
   "source": [
    "Setting up the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23011e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prithvirao/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import concurrent\n",
    "import os\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "\n",
    "from Custom_Utils.processor import adding_unknown, tokenizer, load_birkbeck_file,evaluate_models\n",
    "from Custom_Utils.ngram_model import SimpleNGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bb28b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    os.makedirs(model.model_loc, exist_ok=True)\n",
    "    with open(os.path.join(model.model_loc, f'{model.n}-gram-counts.pickle'), 'wb') as handle:\n",
    "        pickle.dump(model.n_gram_counts, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_model(model):\n",
    "    with open(os.path.join(model.model_loc, f'{model.n}-gram-counts.pickle'), 'rb') as handle:\n",
    "        model.n_gram_counts = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8adbe3",
   "metadata": {},
   "source": [
    "Downloading the brown corpus to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a70f0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/prithvirao/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/prithvirao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04cc105",
   "metadata": {},
   "source": [
    "# Training the models using brown corpus and testing all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c4e7e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram model prediction: {1: [('the', 0.054305789145672016)], 5: [('the', 0.054305789145672016), ('<unknown>', 0.049470570749800345), (',', 0.04527565013508343), ('<s>', 0.044502636086562054), ('<e>', 0.044502636086562054)], 10: [('the', 0.054305789145672016), ('<unknown>', 0.049470570749800345), (',', 0.04527565013508343), ('<s>', 0.044502636086562054), ('<e>', 0.044502636086562054), ('.', 0.038988313983405035), ('of', 0.028260027645341777), ('and', 0.02239334773291899), ('to', 0.02030170831448012), ('a', 0.018014487028343074)]}\n",
      "\n",
      "2-gram model prediction: {1: [(',', 0.0039904229848363925)], 5: [(',', 0.0039904229848363925), ('.', 0.002154828411811652), ('``', 0.0010375099760574621), ('and', 0.0010375099760574621), ('of', 0.0009577015163607343)], 10: [(',', 0.0039904229848363925), ('.', 0.002154828411811652), ('``', 0.0010375099760574621), ('and', 0.0010375099760574621), ('of', 0.0009577015163607343), ('when', 0.00047885075818036713), ('the', 0.0003990422984836393), ('at', 0.0003990422984836393), ('with', 0.0003990422984836393), ('he', 0.0003990422984836393)]}\n",
      "\n",
      "3-gram model prediction: {1: [('the', 8.118860112040269e-05)], 5: [('the', 8.118860112040269e-05), ('fulton', 8.118860112040269e-05), ('county', 8.118860112040269e-05), ('grand', 8.118860112040269e-05), ('jury', 8.118860112040269e-05)], 10: [('the', 8.118860112040269e-05), ('fulton', 8.118860112040269e-05), ('county', 8.118860112040269e-05), ('grand', 8.118860112040269e-05), ('jury', 8.118860112040269e-05), ('said', 8.118860112040269e-05), ('friday', 8.118860112040269e-05), ('an', 8.118860112040269e-05), ('investigation', 8.118860112040269e-05), ('of', 8.118860112040269e-05)]}\n",
      "\n",
      "5-gram model prediction: {1: [('the', 8.118860112040269e-05)], 5: [('the', 8.118860112040269e-05), ('fulton', 8.118860112040269e-05), ('county', 8.118860112040269e-05), ('grand', 8.118860112040269e-05), ('jury', 8.118860112040269e-05)], 10: [('the', 8.118860112040269e-05), ('fulton', 8.118860112040269e-05), ('county', 8.118860112040269e-05), ('grand', 8.118860112040269e-05), ('jury', 8.118860112040269e-05), ('said', 8.118860112040269e-05), ('friday', 8.118860112040269e-05), ('an', 8.118860112040269e-05), ('investigation', 8.118860112040269e-05), ('of', 8.118860112040269e-05)]}\n",
      "\n",
      "10-gram model prediction: {1: [('the', 8.118860112040269e-05)], 5: [('the', 8.118860112040269e-05), ('fulton', 8.118860112040269e-05), ('county', 8.118860112040269e-05), ('grand', 8.118860112040269e-05), ('jury', 8.118860112040269e-05)], 10: [('the', 8.118860112040269e-05), ('fulton', 8.118860112040269e-05), ('county', 8.118860112040269e-05), ('grand', 8.118860112040269e-05), ('jury', 8.118860112040269e-05), ('said', 8.118860112040269e-05), ('friday', 8.118860112040269e-05), ('an', 8.118860112040269e-05), ('investigation', 8.118860112040269e-05), ('of', 8.118860112040269e-05)]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_list = brown.sents()\n",
    "tokenized_sent, vocabulary = tokenizer(new_list)\n",
    "model_train_data = adding_unknown(tokenized_sent, vocabulary)\n",
    "test_sentence_tokens=[\"The\", \"morning\"]\n",
    "ns = [1, 2, 3, 5, 10]\n",
    "for n in ns:\n",
    "    model = SimpleNGram(n=n, model_loc='models', vocabulary=vocabulary)\n",
    "    model.fit(model_train_data)\n",
    "    save_model(model)\n",
    "    print(f\"{n}-gram model prediction: {model.get_suggestions(test_sentence_tokens)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33202516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b38f75be",
   "metadata": {},
   "source": [
    "# Loading a small Birkbeck APPLING1DAT file as a validation file with handful enteries to execute for all models and evaluating them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47f09863",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = load_birkbeck_file(file_loc='Data/APPLING1DAT_validting.643')\n",
    "tokenized_sent, a = tokenizer(testing_data['previous-tokens'].values.tolist(), remove_empty=False)\n",
    "model_testing_data = adding_unknown(tokenized_sent, vocabulary)\n",
    "testing_data['final-test'] = model_testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "040760ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['i', 'felt', 'very'], ['when', 'the'], ['in', 'the'], ['i', 'thought', 'it', 'was', 'a'], ['everything'], ['the', 'morning'], ['the', 'hunters']]\n"
     ]
    }
   ],
   "source": [
    "print(model_testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffb50e7",
   "metadata": {},
   "source": [
    "Using the same evaluation method as used in previous spell check model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b920d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 7/7 [00:00<00:00, 7414.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S@k average of 1-gram model\n",
      "******************************\n",
      "success_1 average: 0.0\n",
      "success_10 average: 0.0\n",
      "success_5 average: 0.0\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 7/7 [00:00<00:00, 7245.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S@k average of 2-gram model\n",
      "******************************\n",
      "success_1 average: 0.0\n",
      "success_10 average: 0.14285714285714285\n",
      "success_5 average: 0.14285714285714285\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 7/7 [00:00<00:00, 5456.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S@k average of 3-gram model\n",
      "******************************\n",
      "success_1 average: 0.0\n",
      "success_10 average: 0.0\n",
      "success_5 average: 0.0\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "queries = [{} for _ in ns]\n",
    "results_eval = [{} for _ in ns]\n",
    "\n",
    "for i, n in enumerate(ns):\n",
    "    model = SimpleNGram(n=n, model_loc='models', vocabulary=vocabulary)\n",
    "    load_model(model)\n",
    "    argument_list = model_testing_data\n",
    "    suggestions = []\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        for result in executor.map(model.get_suggestions, argument_list):\n",
    "            suggestions.append(result)\n",
    "\n",
    "    query = queries[i]\n",
    "    result_eval = results_eval[i]\n",
    "    evaluate_models(queries[i],results_eval[i],suggestions,testing_data,model_testing_data,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf10aed",
   "metadata": {},
   "source": [
    "# Loading complete Birkbeck APPLING1DAT file and evaluating it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b8326e",
   "metadata": {},
   "source": [
    "The 3-gram, 5-gram, 10-gram models take very much time to compute even after multiprocessing and we lack the computational power, thus we are showing 1-gram and 2-gram implementation using the same code used for the validation dataset on the complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0080cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = load_birkbeck_file(file_loc='Data/APPLING1DAT.643')\n",
    "tokenized_sent, a = tokenizer(testing_data['previous-tokens'].values.tolist(), remove_empty=False)\n",
    "model_testing_data = adding_unknown(tokenized_sent, vocabulary)\n",
    "testing_data['final-test'] = model_testing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084a8791",
   "metadata": {},
   "source": [
    "Comment the below single line of code inorder to evaluate all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a5e68e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b703361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 198/198 [00:00<00:00, 11843.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S@k average of 1-gram model\n",
      "******************************\n",
      "success_1 average: 0.0\n",
      "success_10 average: 0.0\n",
      "success_5 average: 0.0\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████████████████████████████████| 198/198 [00:00<00:00, 11494.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S@k average of 2-gram model\n",
      "******************************\n",
      "success_1 average: 0.007407407407407408\n",
      "success_10 average: 0.014814814814814815\n",
      "success_5 average: 0.007407407407407408\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "queries = [{} for _ in ns]\n",
    "results_eval = [{} for _ in ns]\n",
    "\n",
    "for i, n in enumerate(ns):\n",
    "    model = SimpleNGram(n=n, model_loc='models', vocabulary=vocabulary)\n",
    "    load_model(model)\n",
    "    argument_list = model_testing_data\n",
    "    suggestions = []\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        for result in executor.map(model.get_suggestions, argument_list):\n",
    "            suggestions.append(result)\n",
    "\n",
    "    query = queries[i]\n",
    "    result_eval = results_eval[i]\n",
    "    evaluate_models(queries[i],results_eval[i],suggestions,testing_data,model_testing_data,n)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399455c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
